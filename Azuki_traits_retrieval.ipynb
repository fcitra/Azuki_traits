{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y-YJHHUFVGuM"
      },
      "outputs": [],
      "source": [
        "# Created by @fcitra on 17 Sept 2022\n",
        "# For bugs, contact hello.fcitra@gmail.com "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary functions\n",
        "\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "vAQMgyfY0kbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input collection data \n",
        "\n",
        "contract = \"0xED5AF388653567Af2F388E6224dC7C4b3241C544\" #Azuki contract\n",
        "collection_size = 10000 #Azuki collection size "
      ],
      "metadata": {
        "id": "KxHDGDy2YBtT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create placeholders for data of each token\n",
        "traits_all_tokens = [] # Store token id\n",
        "token_id_all_tokens = [] # \n",
        "trait_count_all_tokens = []\n",
        "\n",
        "# Retrieve traits of each token\n",
        "for i in range(collection_size): # Re-iterate for the whole collection\n",
        "  token_id = i\n",
        "  single_asset_url = \"https://api.opensea.io/asset/\" + contract + \"/\" + str(token_id) # Create OpenSea API URL\n",
        "  single_asset = requests.get(single_asset_url).json() # Request trait for each from OpenSea API\n",
        "  token_traits = single_asset['traits'] # Store trait data from OpenSea API\n",
        "  no_of_traits = len(token_traits) # Count the number of traits\n",
        "  trait_list = []\n",
        "  for j in range(no_of_traits): # Retrieve value of each trait, iterated for all traits\n",
        "    trait_list.append(token_traits[j]['value']) # Store trait value of a single token\n",
        "  traits_all_tokens.append(trait_list) # Store trait value for each token in the whole collection\n",
        "  token_id_all_tokens.append(token_id)\n",
        "  trait_count_all_tokens.append(no_of_traits) # Store trait count for each token in the whole collection"
      ],
      "metadata": {
        "id": "ZWZLt8--WbE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe from list\n",
        "azuki_traits_df = pd.DataFrame(list\n",
        "                               (zip(token_id_all_tokens, trait_count_all_tokens, traits_all_tokens)),\n",
        "                               columns = ['Token_id', 'Trait_count', 'Trait_list'])"
      ],
      "metadata": {
        "id": "VYUu_zaaZe1M"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "azuki_traits_df['Trait_list']"
      ],
      "metadata": {
        "id": "lPOFne61wn-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "azuki_traits_df = azuki_traits_df.astype(str).replace({\"\\[\":\"\", \"\\]\":\"\",\"\\'\":\"\" }, regex=True)"
      ],
      "metadata": {
        "id": "xC-Lb37jx62K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "azuki_traits_df.to_csv('azuki_traits.csv')"
      ],
      "metadata": {
        "id": "a4dFczl3zx83"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}